{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.scalers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalers \n",
    "> Utils for scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch as t\n",
    "# import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Scaler(object):\n",
    "    def __init__(self, technique):\n",
    "        \"\"\" Scale features by shifting their center and scaling.\n",
    "\n",
    "        The Scaler class contains methods to preprocess features, centering them\n",
    "        and bounding their variance. Centering and scaling are computed independently \n",
    "        on each series' feature. \n",
    "\n",
    "            Parameters:\n",
    "                technique: str\n",
    "                    The scaling technique is defined by the scale `technique` parameter that \n",
    "                    takes one  of the following values: \n",
    "                    ['Std', 'Median', 'Norm', 'Norm1', 'Invariant']\n",
    "\n",
    "            Attributes:\n",
    "                center_: array of shape (n_series, n_features) or None\n",
    "                    Per feature/series center (mean/median) of the data to center around zero.\n",
    "\n",
    "                scale_: array of shape (n_series, n_features, ) or None\n",
    "                    Per feature/series scaling of the data to bound variance.\n",
    "\n",
    "            References:\n",
    "            [1] LeCun, Y., Bottou, L., Orr, G. B., & MÃ¼ller, K. R. (1998). Effcient backprop. \n",
    "                In Neural Networks: Tricks of the Trade pp. 9{50). Berlin, Heidelberg: Springer \n",
    "                Berlin Heidelberg. URL: https://link.springer.com/chapter/10.1007/3-540-49430-8_2.\n",
    "\n",
    "            [2] Kuhn, M., & Johnson, K. (2019). Feature engineering and selection: A practical \n",
    "                approach for predictive models. CRC Press.\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        assert (technique in ['std']), 'Technique not defined'\n",
    "        self.technique = technique\n",
    "        self.center_ = None\n",
    "        self.scale_ = None\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, X, mask):\n",
    "        \"\"\" Scale features of X according to the scale `technique`.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            X: array-like of shape (n_series, n_features, n_time)\n",
    "                The input data to transform.\n",
    "\n",
    "            mask: array-like of shape (n_series, n_time)\n",
    "                Mask on which to compute the center_ and scale_. You can use it to \n",
    "                separate available and in-sample and out-sample data.\n",
    "                So that test set leakage is avoided.\n",
    "\n",
    "        \"\"\"\n",
    "        if mask is None:\n",
    "            mask = t.ones((X.shape))\n",
    "        else:\n",
    "            mask = mask[:, None, :]\n",
    "\n",
    "        if self.technique == 'std':\n",
    "            self.center_, self.scale_ = fit_std_scaler(X, mask)\n",
    "\n",
    "        self.fitted = True\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert self.fitted, 'Scaler must be fitted before transforming'\n",
    "\n",
    "        if self.technique == 'std':\n",
    "            X_scaled = transform_std_scaler(X, center=self.center_, scale=self.scale_)\n",
    "        \n",
    "        nan_before_scale = t.sum(t.isnan(X))\n",
    "        nan_after_scale = t.sum(t.isnan(X_scaled))\n",
    "\n",
    "        assert nan_before_scale == nan_after_scale, 'Scaler induced nans'\n",
    "\n",
    "        return X_scaled\n",
    "\n",
    "    def inverse_transform_y(self, Y, ts_idxs):\n",
    "        \"\"\" Return inverse-transformed input Y, defined by the scale `technique`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            Y: array-like of shape (n_windows, n_time)\n",
    "                The input data to transform.\n",
    "            ts_idxs: array-like of shape (n_windows)\n",
    "                Time-series index for each n_window in Y.\n",
    "                Indexes must be within [0, n_series)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Y_inv_scaled: array-like of shape (n_windows, n_time)\n",
    "                Transformed data.\n",
    "        \"\"\"\n",
    "        assert self.fitted, 'Scaler must be fitted before transforming'\n",
    "\n",
    "        # 0 index target variable in center and\n",
    "        # scale (inherited from ts_tensor in Dataset object)\n",
    "        center = self.center_[ts_idxs, 0]\n",
    "        scale  = self.scale_[ts_idxs, 0]\n",
    "\n",
    "        if self.technique == 'std':\n",
    "            Y_inv_scaled = inv_std_scaler(X=Y,\n",
    "                                          center=center, \n",
    "                                          scale=scale)\n",
    "\n",
    "        return Y_inv_scaled\n",
    "\n",
    "# Standard scaler\n",
    "def fit_std_scaler(X, mask):\n",
    "    \"\"\"\n",
    "    Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "    The scaled features are computed as:\n",
    "\n",
    "    $$ \\tilde{X} = (X-\\mu) / \\sigma $$\n",
    "\n",
    "    \"\"\"\n",
    "    means = t.sum(X*mask, dim=-1, keepdim=True) / t.sum(mask, dim=-1, keepdim=True)\n",
    "    stds = t.sqrt( t.sum( mask*(X-means)**2, dim=-1, keepdim=True)/ \\\n",
    "                    t.sum(mask, dim=-1, keepdim=True) )\n",
    "\n",
    "    return means, stds\n",
    "\n",
    "def transform_std_scaler(X, center, scale):\n",
    "    return (X - center) / scale\n",
    "\n",
    "def inv_std_scaler(X, center, scale):\n",
    "    \"\"\"\n",
    "    Scale back the data to the original representation.\n",
    "\n",
    "    The scaled features are computed as:\n",
    "\n",
    "    $$ X = \\tilde{X} * \\sigma +\\mu $$\n",
    "\n",
    "    \"\"\"\n",
    "    return (X * scale) + center\n",
    "\n",
    "# # Norm\n",
    "# def norm_scaler(x, mask):    \n",
    "#     x_max = np.max(x[mask==1])\n",
    "#     x_min = np.min(x[mask==1])\n",
    "    \n",
    "#     x = (x - x_min) / (x_max - x_min)\n",
    "#     return x, x_min, x_max\n",
    "\n",
    "# def inv_norm_scaler(x, x_min, x_max):\n",
    "#     return x * (x_max - x_min) + x_min\n",
    "\n",
    "# # Norm1\n",
    "# def norm1_scaler(x, mask):\n",
    "#     x_max = np.max(x[mask==1])\n",
    "#     x_min = np.min(x[mask==1])\n",
    "\n",
    "#     x = (x - x_min) / (x_max - x_min)\n",
    "#     x = x * (2) - 1\n",
    "#     return x, x_min, x_max\n",
    "\n",
    "# def inv_norm1_scaler(x, x_min, x_max):\n",
    "#     x = (x + 1) / 2\n",
    "#     return x * (x_max - x_min) + x_min\n",
    "\n",
    "# # Median\n",
    "# def median_scaler(x, mask):\n",
    "#     x_median = np.median(x[mask==1])\n",
    "#     x_mad = sm.robust.scale.mad(x[mask==1])\n",
    "#     if x_mad == 0:\n",
    "#         x_mad = np.std(x[mask==1], ddof = 1) / 0.6744897501960817\n",
    "#     x = (x - x_median) / x_mad\n",
    "#     return x, x_median, x_mad\n",
    "\n",
    "# def inv_median_scaler(x, x_median, x_mad):\n",
    "#     return x * x_mad + x_median\n",
    "\n",
    "# # Invariant\n",
    "# def invariant_scaler(x, mask):\n",
    "#     x_median = np.median(x[mask==1])\n",
    "#     x_mad = sm.robust.scale.mad(x[mask==1])\n",
    "#     if x_mad == 0:\n",
    "#         x_mad = np.std(x[mask==1], ddof = 1) / 0.6744897501960817\n",
    "#     x = np.arcsinh((x - x_median) / x_mad)\n",
    "#     return x, x_median, x_mad\n",
    "\n",
    "# def inv_invariant_scaler(x, x_median, x_mad):\n",
    "#     return np.sinh(x) * x_mad + x_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestScaler(unittest.TestCase):\n",
    "    def __init__(self):\n",
    "        t.manual_seed(1)\n",
    "        X_1 = t.randn((7,4,10000))\n",
    "        X_2 = 5*t.randn((7,4,10000)) + 3\n",
    "        self.X = t.cat((X_1, X_2), dim=2)\n",
    "        self.mask = t.ones((7,20000))\n",
    "        self.mask[:,-10000:] = 0\n",
    "        self.scaler = Scaler(technique='std')\n",
    "\n",
    "    def test_std(self):\n",
    "        self.scaler = self.scaler.fit(X=self.X, mask=self.mask)\n",
    "        X_scaled = self.scaler.transform(self.X)\n",
    "        \n",
    "        np.testing.assert_almost_equal(self.scaler.center_.numpy(), np.zeros(self.scaler.center_.shape), decimal=1)\n",
    "        np.testing.assert_almost_equal(self.scaler.scale_.numpy(), np.ones(self.scaler.center_.shape), decimal=1)\n",
    "        np.testing.assert_almost_equal(self.X.numpy(), X_scaled.numpy(), decimal=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TestScaler()\n",
    "test.test_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.scaler.center_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.scaler.center_[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
